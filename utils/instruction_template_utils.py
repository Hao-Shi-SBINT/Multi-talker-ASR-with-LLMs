# preprocess_prompts.py
# -----------------------------------------------------------
# Tiny helper for building the prompt-and-response strings used
# in multi-speaker ASR fine-tuning.
#
# Author: Auto-generated by ChatGPT
# -----------------------------------------------------------

from typing import Tuple

__all__ = ["build_prompt_and_input"]


def build_prompt_and_input(
    prompt: str,
    response: str,
) -> Tuple[str, str]:
    """
    Construct the `<bos_prompt> … <eos_prompt>` and
    `<bos_speech><eos_speech><bos_response> … <eos_response>` strings.

    Parameters
    ----------
    prompt   : str
        The textual prompt (speaker instruction etc.).
    response : str
        The ground-truth transcription / target text.
    do_lower : bool, default=False
        Whether to lowercase both prompt and response.

    Returns
    -------
    prompt_str  : str
    input_str   : str
        The two formatted strings, ready for tokenisation.
    """

    prompt_str = f"<bos_prompt>{prompt}<eos_prompt><bos_speech><eos_speech><bos_response>"
    input_str  = f"{response}<eos_response>"

    return prompt_str, input_str

